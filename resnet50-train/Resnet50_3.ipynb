{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.10-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python361064bitfastaiconda22347a2a37134b828b452e384a09faff",
   "display_name": "Python 3.6.10 64-bit ('fastai': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "Using TensorFlow backend.\n"
    }
   ],
   "source": [
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications import ResNet50\n",
    "from keras.applications.resnet50 import preprocess_input\n",
    "from keras import Model, layers\n",
    "from keras.models import load_model, model_from_json\n",
    "from keras.preprocessing import image #*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = \"data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Found 2319 images belonging to 3 classes.\nFound 574 images belonging to 3 classes.\n"
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    shear_range=10,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    preprocessing_function=preprocess_input)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    input_path + 'train',\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    target_size=(224,224))\n",
    "\n",
    "validation_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input)\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    input_path + 'validation',\n",
    "    shuffle=False,\n",
    "    class_mode='binary',\n",
    "    target_size=(224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "C:\\Users\\tanon\\AppData\\Local\\Continuum\\anaconda3\\envs\\fastai\\lib\\site-packages\\keras_applications\\resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
    }
   ],
   "source": [
    "conv_base = ResNet50(\n",
    "    include_top=False,\n",
    "    weights='imagenet')\n",
    "\n",
    "for layer in conv_base.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = conv_base.output\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dense(128, activation='relu')(x) \n",
    "predictions = layers.Dense(3, activation='softmax')(x)\n",
    "model = Model(conv_base.input, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam()\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEP_SIZE_TRAIN=train_generator.n\n",
    "STEP_SIZE_VALID=validation_generator.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Epoch 1/100\n2319/2319 [==============================] - 1101s 475ms/step - loss: 0.0686 - accuracy: 0.9751 - val_loss: 0.0017 - val_accuracy: 0.8881\nEpoch 2/100\n2319/2319 [==============================] - 1129s 487ms/step - loss: 0.0159 - accuracy: 0.9947 - val_loss: 0.1685 - val_accuracy: 0.9231\nEpoch 3/100\n2319/2319 [==============================] - 1157s 499ms/step - loss: 0.0118 - accuracy: 0.9961 - val_loss: 0.4898 - val_accuracy: 0.8621\nEpoch 4/100\n2319/2319 [==============================] - 1164s 502ms/step - loss: 0.0095 - accuracy: 0.9965 - val_loss: 1.3197 - val_accuracy: 0.8953\nEpoch 5/100\n2319/2319 [==============================] - 1117s 482ms/step - loss: 0.0055 - accuracy: 0.9976 - val_loss: 2.2830 - val_accuracy: 0.8867\nEpoch 6/100\n2318/2319 [============================>.] - ETA: 0s - loss: 0.0067 - accuracy: 0.9974"
    }
   ],
   "source": [
    "history = model.fit_generator(generator=train_generator,\n",
    "                              steps_per_epoch=2319,  # added in Kaggle\n",
    "                              epochs=100,\n",
    "                              validation_data=validation_generator,\n",
    "                              validation_steps=574\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir models\n",
    "!mkdir models/keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "model.save('models/keras/model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load\n",
    "model = load_model('models/keras/model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "model.save_weights('models/keras/weights.h5')\n",
    "with open('models/keras/architecture.json', 'w') as f:\n",
    "        f.write(model.to_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load\n",
    "with open('models/keras/architecture.json') as f:\n",
    "    model = model_from_json(f.read())\n",
    "model.load_weights('models/keras/weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_generator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = 'data/validation/glass/glass582.jpg'\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "\n",
    "preds = model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}